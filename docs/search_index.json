[
["index.html", "Notes personnelles : Principes stats, procédures et outils avec R 1 Préambule", " Notes personnelles : Principes stats, procédures et outils avec R Nicolas Bressoud 09 June, 2020 1 Préambule Ce livre a comme objectifs de garder traces des apprentissages réalisés simultanément en stats ainsi qu’en utilisation de R pour les analyses et le rapport des résultats. Il sert donc avant tout de mémoire à l’auteur. On insistera particulièrement sur les bonnes pratiques, les sources pertinentes, et quelques traces de scripts. On présentera également les doutes, les chantiers ouverts et quelques interrogations, soit autant d’éléments qui permettront de jalonner les prochaines étapes d’apprentissage. "],
["environnement-de-travail.html", "2 Environnement de travail 2.1 GitHub et structure des dossiers locaux 2.2 RStudio et packages 2.3 Sublime Text et Packages. 2.4 Scrivener 3 + Zotero + BetterBibText - Rédaction d’articles longs", " 2 Environnement de travail La configuration de travail implique GitHub, RStudio, Sublime Text. 2.1 GitHub et structure des dossiers locaux On dispose d’un compte chez GitHub. Le compte est lié à 3 machines (2 macbooks et un pc). Le commit et le push se réalisent depuis RStudio directement. Sur chaque machine, on s’offre une solution user friendly avec GitHub Desktop, bien que RStudio permette de réaliser directement dans le programme le commit et le push. Sur chaque machine, on dispose d’une structure de type Documents &gt; GitHub &gt; r-projects (attention à la casse). Le dossier r-projects contient autant de sous-dossiers que de projets à analyser. Chaque sous-dossier a un nom structuré ainsi (attention à la casse) : contexteannée_initialesauteurprincipal (par exemple : dupp2019_cr ou crips2019_lv). Dans chaque sous-dossier: un fichier Rproj est disponible et il porte le nom du sous-dossier un fichier présentant les données brutes (raw) est disponible (en lecture seule de préférence) et il porte un titre de la forme nomsousdossier_raw. Il peut être en format .csv ou .xlsx. Si les données brutes sont sur plusieurs fichiers (dans le cas de plusieurs temps de mesure, p.ex., on les distingue avec l’ajout *_t1*, …) un fichier de script .R intitulé nomsousdossier_script un fichier Rmarkdown .Rmd intitulé nomsousdossier_rapport et rédigé en parallèle du script. Ce rapport général appelle le script pour réaliser les sorties. les sorties de type HTML, pdf, ou image (png, svg) n’obéissent pas à des règles précises. plusieurs rapports peuvent coexister en fonction des destinataires ; ils sont tous une adaptation du rapport “master” décrit plus haut. L’esprit est d’avoir à tout moment sur GitHub une vision claire des modifications réalisées à travers les différentes étapes de mise à jour des fichier (traçabilité de la démarche). De plus, une attention particulière est accordée à l’écriture d’un code avec une grammaire (le plus possible) conventionnelle qui est lisible et commenté, que ce soit dans le script ou dans le rapport Rmarkdown. Le script et le rapport se rédigent en parallèle. Le code suivant est, à notre sens, un exemple de bonne pratique car : les commentaires sont présents, précis et concis les espaces facilitent la lecteur le code n’est pas (à notre connaissance) inutilement répétitif ############### #visualisation# ############### #score échelle HBSC vis_hbs &lt;- d_long_paired %&gt;% ggplot() + aes(x = temps, color = group, y = hbs_sco) + geom_boxplot(alpha = .5) + geom_jitter(size = 5, alpha = .5, position = position_jitterdodge(dodge.width=.7, jitter.width = .2)) + stat_summary(fun = mean, geom = &quot;point&quot;, size = 3, shape = 4) + stat_summary(fun = mean, aes(group = group), geom = &quot;line&quot;) + labs(title = &quot;Mesure des CPS&quot;, y = &quot;Score au HBSC&quot;) + theme(plot.title = element_text(hjust = 0.5)) + scale_color_brewer(&quot;Groupe&quot;, palette = &quot;Set1&quot;) Un autre exemple illustre cette grammaire (on rajoute quelques espaces pour faciliter la lecture et repérer les structures répétitives) : #Création des moyennes de chaque questionnaire pour chaque observation d_long &lt;- d_long %&gt;% mutate(hbs_sco = rowMeans(select(.,starts_with(&quot;hbs&quot;)),na.rm =T), pec_sco = rowMeans(select(.,starts_with(&quot;pec&quot;)),na.rm =T), be_sco = rowMeans(select(.,starts_with(&quot;be&quot;)) ,na.rm =T), est_sco = rowMeans(select(.,starts_with(&quot;est&quot;)),na.rm =T), cli_sco = rowMeans(select(.,starts_with(&quot;cli&quot;)),na.rm =T), sou_sco = rowMeans(select(.,starts_with(&quot;sou&quot;)),na.rm =T), mot_sco = rowMeans(select(.,starts_with(&quot;hbs&quot;)),na.rm =T)) Une source pour la grammaire du codage peut être consultée à l’adresse : https://www.inwt-statistics.com/read-blog/inwts-guidelines-for-r-code.html 2.2 RStudio et packages On dispose en l’état de la version 4.0.0 de R ainsi que de la version 1.2.5042 de RStudio. Différents ajouts comme Xquartz ou des modules liés à LaTeX sont également installés, mais honnêtement, on a perdu de vue leur rôle plus ou moins nécessaire sachant que LaTeX est certes nécessaire pour les sorties PDF sans que toutes les extensions liées à LaTex le soient… Ce sera à clarifier au prochain clean install. Dans R, les packages suivants sont installés: tidyverse, suite de packages pour travailler de manière tidy (bien rangé) : ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, forcats. readxl, permet de lire et importer les fichiers .xlsx. bookdown, permet de réaliser à peu de frais le présent livre En principe, pour des raisons d’élégance du code, on cherche à limiter la sur-installation de nouveaux packages. Il s’agit d’explorer ce que les packages installés ont à offrir avant de courir sur d’autres fonctions vues sur le web. 2.3 Sublime Text et Packages. L’utilisation de Sublime Tex est ergonomique. Les packages du logiciel permettent de travailler comme R Studio, avec toutefois un environnement plus aéré et propice à la rédaction avec des codes couleurs agréables. Il est complémentaire à RStudio mais peut carrément le remplacer pour certaines courtes étapes de rédaction. Les packages installés sont: sur PC : R-Box, R-IDE, LSP sur MAC : R-Box, SendCode On doit encore clarifier comment lier sur PC et MAC GitHub. Mais ce n’est pas prioritaire. GitHub sur Sublime Text ??? Emmet, git, sublime github. https://gist.github.com/KedrikG/f7b955dc371b1204ec76ce862e2dcd2e 2.4 Scrivener 3 + Zotero + BetterBibText - Rédaction d’articles longs On doit déterminer comment travailler en RMarkdown pour des articles longs via Scrivener 3. Ce logiciel a l’avantage de facilement découper l’article en plusieurs zones de travail et “fusionner” le tout à l’export. De plus, on peut lier la rédaction à Zotero via un fichier Bibtex ce qui est très intéressant. On pense aussi à rassembler les éléments rédigés dans Scrivener et compiler le tout avec Bookdown sous R. Un hypothétique *workflow\" serait : script dans R &gt; ébauche de rapport dans R (RMarkdown) &gt; copier/coller de l’ébauche de rapport dans Scrivener &gt; rédaction dans Scrivener en compatibilité avec Bookdown &gt; export de Scrivener dans R &gt; préparation de la sortie avec Bookdown. Mais ce n’est pas optimal. Notre souhait est de pouvoir, p.ex., modifier une donnée dans la source des données (le fichier brut) et cliquer sur un (voire deux) boutons pour mettre à jour l’article final ! On n’y est pas encore !! L’organisation de la rédaction est un gros chantier qui n’est pas du tout structuré en l’état. "],
["préparation-des-données.html", "3 Préparation des données 3.1 Bonnes pratiques dans le système de récolte des données (Qualtrics, …) 3.2 Premières étapes dans R (en principe, les noms des variables sont sains)", " 3 Préparation des données Au sein de ce chapitre, on cherche à atteindre le double objectif de/d’ : expliciter une manière que l’on espère élégante et efficace (minimum d’effort pour le maximum d’efficacité) de préparer les données. se conformer aux apprentissages et pratiques en traitement des données (et progresser). On cherche dans la mesure du possible à toujours travailler avec des tidy datas et à utiliser en priorité les fonctions de la série de packages de tidyverse. 3.1 Bonnes pratiques dans le système de récolte des données (Qualtrics, …) Chaque participant·e reçoit un id partiellement anonymisé. Il est fourni par le chercheur (et n’est pas construit par le ou la participant·e). L’id ne contient que des chiffres pour simplifier le problème des majuscules/minuscules à la saisie et éviter les confusions entre le zéro et la lettre o (oui oui, c’est du vécu). Ceci signifie que l’id dispose d’une structure qui permet de/d’ : évaluer son authenticité faciliter la catégorisation des données repérer efficacement les id et leur catégorisation dans les traitement ultérieurs. exemple : un id comme 12.47.694 est structuré comme suit classe12.constantearbitraire47.nombrealéatoireà3chiffres. Chaque id est vérifié dans Qualtrics, ce qui signifie qu’un·e participant·e doit confirmer l’id pour que le système passe à la suite. On relève aussi l’intérêt de demander à l’utilisateur·trice de confirmer son groupe d’appartenance en cochant un facteur dans une liste imposée dans Qualtrics. Ceci a l’avantage de repérer les saisies fantasques (une personne met un id bidon / un·e participant·e s’inscrit avec le bon id mais dans le mauvais groupe, …). Dans la préparation des données, il semble que l’on gagne ainsi un temps important pour trier les données valables et que la confiance dans les données s’en trouve augmentée. On relève toutefois une faiblesse : le code n’est pas 100% anonyme et on peut toujours remonter à un groupe de participant·es. Il faut alors en amont s’engager à détruire le document qui a permis la génération des id. Chaque questionnaire est identifié par 3 premières lettre significatives, le nombre d’items et un _: exemple : Questionnaire sur la motivation scolaire en 13 items devient mot13. Ensuite, chacun des items est proprement nommé par ordre d’apparition : exemple : mot13_1, mot13_2, …, mot13_13 (il semble que Qualtrics ajoute par défaut le underscore_ ) 3.2 Premières étapes dans R (en principe, les noms des variables sont sains) On commence par le chargement des packages et l’importation du ou des fichiers de données. Dans cet exemple, on prend le cas (plus complexe) où nous devons gérer et associer deux data frames. library(tidyverse) library(readxl) # Importation des données Qualtrics à disposition ---- d_t1_raw &lt;- read_excel(&quot;crips2019_lv_raw_t1.xlsx&quot;) d_t2_raw &lt;- read_excel(&quot;crips2019_lv_raw_t2.xlsx&quot;) 3.2.1 ajout de la variable de temps dans chaque df Dans cet exemple, on règle en même temps le problème des id qui contiennent des majuscules. #Ajout de la variable temps sur chaque df et normalisation des id en minuscule. d_t1 &lt;- d_t1_raw %&gt;% mutate(temps=&quot;temps 1&quot;, id=tolower(id)) d_t2 &lt;- d_t2_raw %&gt;% mutate(temps=&quot;temps 2&quot;, id=tolower(id)) Les items à inverser sont traités en étant strictement remplacés via la fonction mutate() dans le cadre de l’enregistrement d’un nouveau data frame. R permet de remonter les changements donc cet écrasement n’empêche pas la vérification des processus, étape par étape. Ce procédé d’écrasement facilite l’analyse de la cohérence interne ou le calcul des scores par la suite (cf. chapitre description). La variable qui contient le score global de chaque questionnaire par participant·e porte l’extension sco : exemple : mot13_sco est la variable de score total de mot13_1 à mot13_13 avec les variables qui ont été inversées. "],
["description-des-données.html", "4 Description des données 4.1 Princpes 4.2 Procédures 4.3 Tableaux 4.4 Plots", " 4 Description des données 4.0.1 Obtenir une synthèse de données #Quelques données sur l&#39;état des participants au Temps 1 et au Temps 2 avant suppression des ID non-membres d&#39;une paire entre T1 et T2. d_t1_sum &lt;- d_t1 %&gt;% group_by(group,sex) %&gt;% summarise(n=n(), age_moy=round(mean(age), digits=1)) 4.1 Princpes 4.2 Procédures 4.3 Tableaux 4.4 Plots intégrer mes trouvailles de crips2019 et ce qu’un plot doit montrer. Travail avec Zoe. Notes à intégrer : Réaliser des boxplots avec barres d’erreurs [ ] –&gt; plutôt utiliser select des variables ou filter des participants gather –&gt; 1er argument nom et 2ème argument valeur set.sid dans Rmarkdown pour figer les aléatoires, p.ex. le jitter pour pas que ça change à chaque lancement. installer des kits de couleurs au besoin. shape : les numéros correspondent à des formes de points. geom_line : 3 arguments minimum. avec group. –&gt; pourquoi “group” et pourquoi “1”. Alt + N = ~ jitter –&gt; position et positionjitterdodge pour comparer G et F "],
["rapport.html", "5 Rapport 5.1 Principes 5.2 Procédures clés 5.3 Un mot sur les normes APA 5.4 Un mot sur Bookdown et GitHub", " 5 Rapport 5.1 Principes Avec ressources (fameux document PDF de CS durant le pre-doc) Ce qui est attendu dans un document de type rapport. (à l’aide du rapport de ZL et de celui en production pour LV) 5.2 Procédures clés 5.3 Un mot sur les normes APA 5.4 Un mot sur Bookdown et GitHub cf. chapitre 1. "]
]
